var documenterSearchIndex = {"docs":
[{"location":"lowrankapprox/aca/#Adaptive-Cross-Aproximation","page":"Adaptive Cross Approximation","title":"Adaptive Cross Aproximation","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The adaptive cross approximation (ACA) is an adaptive rank revealing matrix factorization approach that computes the factorization of a low-rank matrix bm A^mtimes n ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"    bm A^mtimes n approx widetildebm A^mtimes n =  bm U^mtimes r bm V^rtimes n","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"where ideally","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"lVert bm A^mtimes n - widetildebmA^mtimes n rVert_textF leq varepsilon lVert bm A^mtimes nrVert_textF","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"with the Forbenius norm lVert cdot rVert_mathrmF and the varepsilon the tolerance of the approximation.","category":"page"},{"location":"lowrankapprox/aca/#API","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.aca","category":"page"},{"location":"lowrankapprox/aca/#Example","page":"Adaptive Cross Approximation","title":"Example","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"using FastBEAST\nusing StaticArrays\nusing LinearAlgebra\n\nfunction OneoverRkernel(testpoint::SVector{3,T}, sourcepoint::SVector{3,T}) where T\n    if isapprox(testpoint, sourcepoint, rtol=eps()*1e1)\n        return 0.0\n    else\n        return 1.0 / (norm(testpoint - sourcepoint))\n    end\nend\n\nfunction assembler(kernel, testpoints, sourcepoints)\n    kernelmatrix = zeros(\n        promote_type(eltype(testpoints[1]),eltype(sourcepoints[1])), \n        length(testpoints),\n        length(sourcepoints)\n    )\n\n    for i in eachindex(testpoints)\n        for j in eachindex(sourcepoints)\n            kernelmatrix[i,j] = kernel(testpoints[i], sourcepoints[j])\n        end\n    end\n\n    return kernelmatrix\nend\n\nfunction assembler(kernel, matrix, testpoints, sourcepoints)\n    for i in eachindex(testpoints)\n        for j in eachindex(sourcepoints)\n            matrix[i,j] = kernel(testpoints[i], sourcepoints[j])\n        end\n    end\nend\n\nN=1000\nspoints = [@SVector rand(3) for i = 1:N]\ntpoints = 0.1*[@SVector rand(3) for i = 1:N] + [SVector(2.0, 0.0, 0.0) for i = 1:N]\n@views OneoverRkernelassembler(matrix, tdata, sdata) = assembler(\n    OneoverRkernel, matrix, tpoints[tdata], spoints[sdata]\n)\nlm = LazyMatrix(OneoverRkernelassembler, Vector(1:N), Vector(1:N), Float64)\nU, V = aca(lm; tol=1e-4)\n","category":"page"},{"location":"lowrankapprox/aca/#Convergence-Criteria","page":"Adaptive Cross Approximation","title":"Convergence Criteria","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The computation of the true error of the factorization after the kth iteration is inefficient. Therefore, typically an approximation of the error is used.  This package provides the following convergence criteria.","category":"page"},{"location":"lowrankapprox/aca/#Standard-Convergence-Criterion","page":"Adaptive Cross Approximation","title":"Standard Convergence Criterion","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The standard convergence criterion used in the ACA checks after each iteration if ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"lVert bm u_k rVert lVert bm v_k rVert leq varepsilon lVert widetildebmA_k^mtimes n rVert_textF ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"where lVert widetildebmA^mtimes n rVert_textF can be computed efficiently by","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"    lVert widetildebmA_k^mtimes n rVert_textF^2 = lVert widetildebmA_k-1^mtimes n rVert_textF^2 + 2 mathcalRleft sum_j=1^k-1 (bm u_j^ast bm u_k) (bm v_j^ast bm v_k)right + (bm u_kbm v_k)^2","category":"page"},{"location":"lowrankapprox/aca/#API-2","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.Standard","category":"page"},{"location":"lowrankapprox/aca/#Random-Sampling-Convergence-Criterion","page":"Adaptive Cross Approximation","title":"Random Sampling Convergence Criterion","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The random sampling convergence criterion checks the mean true error of the approximation for a given subset of matrix entries in bm A^mtimes n after k iterations. Convergence is met if ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"sqrttextmean(bme_r^2)mn leq varepsilon lVert widetildebmA_k^mtimes n rVert_F","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"where bme_r contains the true error for the set of random samples after the kth iteration.","category":"page"},{"location":"lowrankapprox/aca/#API-3","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.RandomSampling\nFastBEAST.RandomSampling(::Type{K}; factor=real(K)(1.0), nsamples=0) where K","category":"page"},{"location":"lowrankapprox/aca/#CCC","page":"Adaptive Cross Approximation","title":"Combined Convergence Criterion","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The combined convergence criterion checks both the standard and random sampling criterion resulting in ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"textmax(lVert bm u_k rVert lVert bm v_k rVertsqrttextmean(bme_r^2)mn) leq varepsilon lVert widetildebmA_k^mtimes n rVert_F","category":"page"},{"location":"lowrankapprox/aca/#API-4","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.Combined\nFastBEAST.Combined(::Type{K}; factor=real(K)(1.0), nsamples=0) where K","category":"page"},{"location":"lowrankapprox/aca/#Pivoting-Strategies","page":"Adaptive Cross Approximation","title":"Pivoting Strategies","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The rows and columns of bm A^m times n used for the factorization are selected following a so called pivoting strategy. This package provides the following pivoting strategies.","category":"page"},{"location":"lowrankapprox/aca/#standardpiv","page":"Adaptive Cross Approximation","title":"Standard Partial Pivoting","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The standard partial pivoting selects the next row or column by the maximum value in modulo of the last column or row. ","category":"page"},{"location":"lowrankapprox/aca/#API-5","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.MaxPivoting\nFastBEAST.MaxPivoting(;firstindex=1)","category":"page"},{"location":"lowrankapprox/aca/#Fill-Distance-Pivoting","page":"Adaptive Cross Approximation","title":"Fill-Distance Pivoting","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The fill-distance pivoting selects the rows (or the columns) based on geometrical considerations, while the corresponding columns (or rows) are selected by the standard partial pivoting. The fill-distance requires for each row (or column) a corresponding node with a position which might be the vertex, edge, or face where a basis function is defined.  For a matrix A^mtimes n we define the set X comprising all nodes corresponding to the rows. The rows used for the factorization are then selected such that the fill-distance ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"    h_X_k X = mathrmsup_xin Xmathrmdist(x X_k)","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"is minimized from step k to step k+1, where X_k subseteq X contains all nodes that are already selected. ","category":"page"},{"location":"lowrankapprox/aca/#API-6","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.FillDistance\nFastBEAST.FillDistance(pos::Vector{SVector{3, F}}) where F <: Real","category":"page"},{"location":"lowrankapprox/aca/#MFDPivoting","page":"Adaptive Cross Approximation","title":"Modified Fill-Distance Pivoting","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The modified fill-distance approach is in principle a fast implementation of the fill-distance pivoting with small modifications. The pivoting is also based on the fill-distance ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"    h_X_k X = mathrmsup_xin Xmathrmdist(x X_k)","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"But contrary to the fill-distance pivoting, where a numerically expensive minimization has to be computed the pivots are selected following","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"    i_k = mathrmargmathrmmax_x in X(mathrmdist(x X_k-1))","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The first pivot is selected as the basis-function closest to the barycenter of the set of nodes X. ","category":"page"},{"location":"lowrankapprox/aca/#API-7","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.ModifiedFillDistance\nFastBEAST.ModifiedFillDistance(pos::Vector{SVector{3, F}}) where F <: Real","category":"page"},{"location":"lowrankapprox/aca/#MRF-Pivoting","page":"Adaptive Cross Approximation","title":"MRF Pivoting","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"The MRF pivoting strategy is an adaptive approach comprising the standard partial pivoting, the modified fill-distance pivoting, and a random sampling pivoting, where the active strategy is selected based on which criterion of the combined convergence criterion is met (details can be found in [4]). ","category":"page"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"<div align=\"center\">\n<img src=\"../../assets/algorithmhz.svg\" width=\"responsive-image\"/>\n</div>\n<br/>","category":"page"},{"location":"lowrankapprox/aca/#API-8","page":"Adaptive Cross Approximation","title":"API","text":"","category":"section"},{"location":"lowrankapprox/aca/","page":"Adaptive Cross Approximation","title":"Adaptive Cross Approximation","text":"FastBEAST.MRFPivoting\nFastBEAST.MRFPivoting(pos::Vector{SVector{I, F}}) where {I, F}","category":"page"},{"location":"apiref/#Coming-Soon...","page":"API Reference","title":"Coming Soon...","text":"","category":"section"},{"location":"fastmethods/fmm/#Fast-Multipole-Method","page":"FMM","title":"Fast Multipole Method","text":"","category":"section"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"The fast multipole method allows to accelerate certain matrix-vector products, originally introduced for N-body problems arising in stellar and molecular dynamics. A matrix-vector product","category":"page"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"bmA bmx  = bmy","category":"page"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"can be computed with the FMM to any specific accuracy varepsilon in mathcalO(N) in storage and time. For the boundary element method (BEM) several implementations of the FMM exist which, in general, are kernel dependent. ","category":"page"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"Adelmann et al. propose in [1] a method using FMM codes for monopole and dipole sources unchanged to evaluate integral expressions in the BEM, which allows to use existing highly optimized implementations of the FMM such as ExaFMM. The approach of Adelmann is called the error correction factor matrix method (ECFMM). ","category":"page"},{"location":"fastmethods/fmm/#Error-Correction-Factor-Matrix-Method","page":"FMM","title":"Error Correction Factor Matrix Method","text":"","category":"section"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"The ECFMM approximates the BEM integrals by a quadrature and treats the quadrature points as monopole and dipole sources, which can be evaluated by the FMM. Approximation errors of the quadrature are corrected during a correction factor step. The matrix-vector product becomes","category":"page"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"bmA bmx approx bmP_2^T(bmG-bmC)bmP_1bmx + bmSbmxapprox y","category":"page"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"where bmS describes all not well-separated interactions, bmG resembles the FMM, bmC corrects the quadrature errors and bmP_1 2 describes the charge for each monopole or dipole source comprising the weight of the quadrature point and the action the test and trial functions. Detailed explanations can be found in FMM/GPU-Accelerated Boundary Element Method for Computational Magnetics and Electrostatics.","category":"page"},{"location":"fastmethods/fmm/#Example","page":"FMM","title":"Example","text":"","category":"section"},{"location":"fastmethods/fmm/","page":"FMM","title":"FMM","text":"using CompScienceMeshes\nusing FastBEAST\n\nŒì = meshsphere(1.0, 0.1)\n\nùì£ = Maxwell3D.singlelayer(wavenumber=k)\nX = raviartthomas(Œì)\n\nT = fmmassemble(ùì£, X, X)","category":"page"},{"location":"manual/manual/#Coming-Soon...","page":"General Usage","title":"Coming Soon...","text":"","category":"section"},{"location":"manual/application/#Coming-Soon...","page":"Application Examples","title":"Coming Soon...","text":"","category":"section"},{"location":"contributing/#Coming-Soon...","page":"Contributing","title":"Coming Soon...","text":"","category":"section"},{"location":"fastmethods/hmatrix/#\\mathcal{H}-Matrix","page":"H-Matrix","title":"mathcalH-Matrix","text":"","category":"section"},{"location":"fastmethods/hmatrix/","page":"H-Matrix","title":"H-Matrix","text":"The mathcalH-Matrix is form of storing boundary element matrices blockwise differentiating compressed low-rank and full-rank matrices. The system matrix in the boundary element method (BEM) is in general dense but has blocks corresponding to well-separated clusters of test- and trial-functions which are low rank and can be compressed. ","category":"page"},{"location":"fastmethods/hmatrix/","page":"H-Matrix","title":"H-Matrix","text":"Using this method the complexity of the computation an approximation with any specific accuracy varepsilon of a boundary element matrix is mathcalO (Nlog N) in time and storage, as well for computing a matrix-vector product.","category":"page"},{"location":"fastmethods/hmatrix/","page":"H-Matrix","title":"H-Matrix","text":"An overview of the low-rank approximation techniques available in this package can be found here","category":"page"},{"location":"fastmethods/hmatrix/#Example","page":"H-Matrix","title":"Example","text":"","category":"section"},{"location":"fastmethods/hmatrix/","page":"H-Matrix","title":"H-Matrix","text":"using BEAST\nusing FastBEAST\nusing CompScienceMeshes\n\nŒì = meshsphere(1.0, 0.1)\n\nùì£ = Maxwell3D.singlelayer(wavenumber=k)\nX = raviartthomas(Œì)\n\nT = hassemble(ùì£, X, X)","category":"page"},{"location":"clustering/#Clustering-Strategies","page":"Clustering","title":"Clustering Strategies","text":"","category":"section"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"This package provides an interface for the ClusterTrees.jl package for preprocessing the geometry and detecting admissible clusters. Admissability criteria are defined for the following clustering algorithms.","category":"page"},{"location":"clustering/#Box-Tree","page":"Clustering","title":"Box Tree","text":"","category":"section"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"The box tree is a classical octree for 3D and an quadtree for 2D geometries.  The admissibility of the clusters is determined by","category":"page"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"beginequation*\n    beginaligned\n    fracsqrt32(l_X_texts+l_X_textt) leq eta textdist_textc(X_texts X_textt) \n    endaligned\nendequation*","category":"page"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"where textdist_textc(cdot cdot) donates the euclidean distance between the center of the two boxes and l_X donates the edge length of the box associated with the cluster X. The parameter eta might be adjusted to the fast method, but should be eta leq 1. ","category":"page"},{"location":"clustering/#Example","page":"Clustering","title":"Example","text":"","category":"section"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"using ClusterTrees\nusing FastBEAST\nusing StaticArrays\n\nN = 1000\nnodes = [@SVector rand(Float64, 3) for i in 1:N]\n\ntree = create_tree(nodes)\n\nnears = SVector{2}[]\nfars = SVector{2}[]\ncomputerinteractions!(tree, tree, nears, fars)","category":"page"},{"location":"clustering/#K-Means-Clustering-Tree","page":"Clustering","title":"K-Means Clustering Tree","text":"","category":"section"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"The K-Means algorithm is a clustering strategy for n-dimensional spaces, in which each cluster is represented by its barycenter and radius.  The admissibility of clusters is determined by ","category":"page"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"beginequation*\n    beginaligned\n    2textmax(textrad(X_textt) textrad(X_texts)) leq Œ∑ textdist_textbc(X_textt X_texts)\n    textdist_textbc(X Y) = textd(textbc(X) textbc(Y)) + textrad(X) + textrad(Y)\n    endaligned\nendequation*","category":"page"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"where textd(cdotcdot) donates the euclidean distance, textrad(X) = textsup(textd(textbc(X) x) x in X) and textbc(cdot) the barycenter of the cluster defined in the K-Means algorithm. The parameter eta might be adjusted to the fast method, but should be eta leq 1. ","category":"page"},{"location":"clustering/#Example-2","page":"Clustering","title":"Example","text":"","category":"section"},{"location":"clustering/","page":"Clustering","title":"Clustering","text":"using ClusterTrees\nusing FastBEAST\nusing StaticArrays\n\nN = 1000\nnodes = [@SVector rand(Float64, 3) for i in 1:N]\n\ntree = create_tree(nodes, KMeansTreeOptions())\n\nnears = SVector{2}[]\nfars = SVector{2}[]\ncomputerinteractions!(tree, tree, nears, fars)","category":"page"},{"location":"#FastBEAST","page":"Introduction","title":"FastBEAST","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This package provides fast methods for boundary element simulations targeting BEAST.jl. ","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Installing FastBEAST is done by entering the package manager (enter ] at the julia REPL) and issuing:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"pkg> add https://github.com/sbadrian/FastBEAST.jl.git","category":"page"},{"location":"#Overview","page":"Introduction","title":"Overview","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The following aspects are implemented (‚úî) and planned (‚åõ):","category":"page"},{"location":"#Available-fast-methods:","page":"Introduction","title":"Available fast methods:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"‚úî H-matrix\n‚úî Kernel independent FMM based on ExaFMM-t\n‚åõ H2-matrix","category":"page"},{"location":"#Available-low-rank-compression-techniques:","page":"Introduction","title":"Available low-rank compression techniques:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"‚úî Adaptive cross approximation \n‚åõ Pseudo-skeleton approximation \n‚åõ CUR matrix approximation ","category":"page"},{"location":"#refs","page":"Introduction","title":"References","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The implementation is based on","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"[1] Adelman, Ross, Nail A. Gumerov, and Ramani Duraiswami. ‚ÄúFMM/GPU-Accelerated Boundary Element Method for Computational Magnetics and Electrostatics.‚Äù IEEE Transactions on Magnetics 53, no. 12 (December 2017): 1‚Äì11. https://doi.org/10.1109/TMAG.2017.2725951.\n[2] Bauer, M., M. Bebendorf, and B. Feist. ‚ÄúKernel-Independent Adaptive Construction of mathcal H^2-Matrix Approximations.‚Äù Numerische Mathematik 150, no. 1 (January 2022): 1‚Äì32. https://doi.org/10.1007/s00211-021-01255-y.\n[3] Heldring, Alexander, Eduard Ubeda, and Juan M. Rius. ‚ÄúImproving the Accuracy of the Adaptive Cross Approximation with a Convergence Criterion Based on Random Sampling.‚Äù IEEE Transactions on Antennas and Propagation 69, no. 1 (January 2021): 347‚Äì55. https://doi.org/10.1109/TAP.2020.3010857.\n[4] Tetzner, Joshua M., and Simon B. Adrian. ‚ÄúOn the Adaptive Cross Approximation for the Magnetic Field Integral Equation.‚Äù Preprint. Preprints, January 26, 2024. https://doi.org/10.36227/techrxiv.170630205.56494379/v1.","category":"page"}]
}
